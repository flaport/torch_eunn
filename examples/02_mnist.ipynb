{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39fba1ef-ec4b-38ca-fca0-0bdb31e294f4"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6efa16c1-f457-45bb-49a3-69e11c7fae18"
   },
   "outputs": [],
   "source": [
    "# standard library\n",
    "import os\n",
    "import gzip\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Other\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EURNN\n",
    "import sys; sys.path.append('..')\n",
    "from torch_eunn import EURNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "num_labels = 10 # Number of different types of labels (1-10)\n",
    "width, height = 28, 28 # width / height of the image\n",
    "num_pixels = width*height\n",
    "\n",
    "# pixel permutation idxs\n",
    "perm_idxs = list(range(num_pixels))\n",
    "np.random.RandomState(seed=0).shuffle(perm_idxs)\n",
    "\n",
    "# reverse pixel permutation idxs\n",
    "rev_perm_idxs = [perm_idxs.index(i) for i in range(num_pixels)]\n",
    "\n",
    "# Training Parameters\n",
    "num_steps = 40000 # Number of training steps to run\n",
    "test_size = 10000 # Test data set size\n",
    "valid_size = 10000 # Validation data set size\n",
    "train_size = 60000 - valid_size # Size of the training set\n",
    "batch_size = 100 # Batch size\n",
    "test_batch_size = 1000 # batch size for calculating the validation/test loss\n",
    "\n",
    "# RNN Parameters\n",
    "num_inputs = 1 # input dimension [1=pixel-by-pixel]\n",
    "num_steps_rnn = num_pixels // num_inputs # sequential dimensionality of rnn\n",
    "num_hidden_rnn = 256 # hidden layer dimension\n",
    "capacity_rnn = 2 # capacity of eunn\n",
    "\n",
    "# Optimization parameters\n",
    "learning_rate = 0.0001 # learning rate\n",
    "\n",
    "# select device ('cuda' or 'cpu')\n",
    "device = 'cuda' # highly recommended to take cuda!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f731214e-9fca-f54d-91be-60475207ba64"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom function to fetch the mnist data from its original source. This function downloads the data from [`http://yann.lecun.com`](http://yann.lecun.com) and saves it as `.npy` in the folder named `mnist_data`. The next time this function is called, the `.npy` files are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_mnist(redownload=False, verbose=True):\n",
    "    ''' Get MNIST data in npy format\n",
    "\n",
    "    Args:\n",
    "        redownload=False (bool): force redownload, even if file already exists\n",
    "    '''\n",
    "    # check if data is already downloaded. If so, do not download again, except\n",
    "    # when explicitly asked to do so\n",
    "    if (os.path.exists('mnist_data/train.npy')\n",
    "        and os.path.exists('mnist_data/test.npy')\n",
    "        and not redownload):\n",
    "        # load files from data folder\n",
    "        return np.load('mnist_data/train.npy'), np.load('mnist_data/test.npy')\n",
    "\n",
    "    # create folders\n",
    "    if not os.path.isdir('mnist_data'):\n",
    "        os.mkdir('mnist_data')\n",
    "\n",
    "    # check if data is already downloaded. If so, do not download again, except\n",
    "    # when explicitly asked to do so\n",
    "    if not (os.path.exists('mnist_data/train_images.gz')\n",
    "        and os.path.exists('mnist_data/train_labels.gz')\n",
    "        and os.path.exists('mnist_data/test_images.gz')\n",
    "        and os.path.exists('mnist_data/test_labels.gz')\n",
    "        and not redownload):\n",
    "        if verbose:\n",
    "            print('downloading mnist data from http://yann.lecun.com/')\n",
    "        # download data\n",
    "        urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'mnist_data/train_images.gz')\n",
    "        urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'mnist_data/train_labels.gz')\n",
    "        urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 'mnist_data/test_images.gz')\n",
    "        urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 'mnist_data/test_labels.gz')\n",
    "\n",
    "    # fill numpy arrays:\n",
    "    train = np.empty((60000,785), dtype='uint8')\n",
    "    test = np.empty((10000,785), dtype='uint8')\n",
    "    \n",
    "    if verbose:\n",
    "        print('extracting mnist data... (takes a while)')\n",
    "\n",
    "    for type, npdata in [('train', train),('test', test)]:\n",
    "        # open the files\n",
    "        with gzip.open('mnist_data/%s_images.gz'%type, 'rb') as data,\\\n",
    "             gzip.open('mnist_data/%s_labels.gz'%type, 'rb') as labels:\n",
    "\n",
    "            # skip the first bytes with metadata of the ubyte file:\n",
    "            data.read(16)\n",
    "            labels.read(8)\n",
    "\n",
    "            # read each byte of the gzip file and save it as a uint8 number\n",
    "            # in the numpy array.\n",
    "            for i in range(npdata.shape[0]):\n",
    "                npdata[i,0] = ord(labels.read(1))\n",
    "                for j in range(784): # append the data after the label\n",
    "                    npdata[i, j+1] = ord(data.read(1))\n",
    "\n",
    "    # save numpy arrays\n",
    "    np.save('mnist_data/train.npy', train)\n",
    "    np.save('mnist_data/test.npy', test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('finished conversion.')\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the custom MNIST data fetcher defined above.\n",
    "\n",
    "The image values are specified by an integer between 0 and 255. We convert these pixel values to a float between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast with the Convolutional Neural Networks, we do a pixel-by-pixel recognition of the digit image where the individial pixels are permuted with a fixed permutation defined by `perm_idx`. This fixed permutation is necessary for good performance of the RNN, as otherwise the the end of the pixel stream contains too many zeros for the RNN to retain its internal state. This is a good benchmark task for a recurrent neural network. The performance of this architecture will obviously be worse than for a convnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "55dd8ffd-6011-49a3-a1fe-c6933c4187b7",
    "_uuid": "840f7b1c60d1a2d5b2222a7c53b2b9d08aac9169",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\ttorch.Size([50000, 784, 1])\n",
      "train labels shape:\ttorch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = fetch_mnist()\n",
    "data = np.vstack([train_data, test_data])\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train_data = data[:-test_size-valid_size]\n",
    "valid_data = data[-test_size-valid_size:-test_size]\n",
    "test_data  = data[-test_size:]\n",
    "\n",
    "def get_values_labels(data):\n",
    "    labels = torch.tensor(data[:,0], dtype=torch.int64, device=device)\n",
    "    values = torch.tensor(data[:,1:][:,perm_idxs]/255, dtype=torch.float32, device=device).view(-1, num_steps_rnn, num_inputs)\n",
    "    return values, labels\n",
    "    \n",
    "train_values, train_labels = get_values_labels(train_data)\n",
    "valid_values, valid_labels = get_values_labels(valid_data)\n",
    "test_values, test_labels = get_values_labels(test_data)\n",
    "\n",
    "print(f'train data shape:\\t{train_values.shape}')\n",
    "print(f'train labels shape:\\t{train_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the different digits by writing a visualization function that reshapes the 784D train and test values into a 28x28 grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_digit(digit_array):\n",
    "    plt.imshow(digit_array.cpu().numpy().reshape(num_pixels)[rev_perm_idxs].reshape(width, height), cmap='Greys')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "show_digit(train_values[31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build a network with two convolutional layers, followed by two fully connected layers. We use the `torch.nn.Module` to create the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden_rnn, capacity_rnn, num_labels):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = EURNN(num_inputs, num_hidden_rnn, capacity=capacity_rnn, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.output_layer = torch.nn.Linear(num_hidden_rnn, num_labels, bias=True)\n",
    "        \n",
    "        # initialize weights\n",
    "        v = np.sqrt(2)/np.sqrt(num_inputs+num_labels)\n",
    "        self.rnn.input_layer.bias.data[:] = 0.01\n",
    "        self.rnn.modrelu.bias.data[:] = 0.01\n",
    "        self.output_layer.bias.data[:] = 0.01\n",
    "        torch.nn.init.uniform_(self.rnn.input_layer.weight.data, -v, v)\n",
    "        torch.nn.init.uniform_(self.output_layer.weight.data, -v, v)\n",
    "        \n",
    "        # move to device\n",
    "        self.to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.output_layer(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e33cb0c7-51ed-02ae-ebb2-dcda12832da6"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_inputs, num_hidden_rnn, capacity_rnn, num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the categorical cross entropy loss for training the model.\n",
    "\n",
    "As optimizer we could use a Gradient Descent optimizer [with or without decaying learning rate] or one of the more sophisticated (and easier to optimize) optimizers like Adam or RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "7fbe419e-7ce2-4d72-bb31-8b27e8161f1b",
    "_uuid": "bb1b6d4fb5504400ed7678d8e95d0a4478b5f409",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# accuracy\n",
    "def accuracy(logits, labels):\n",
    "    return 100*np.mean(np.argmax(logits.data.cpu().numpy(), 1) == labels.data.cpu().numpy())\n",
    "\n",
    "# RMSprop Optimizer\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "32786a5c-0388-412d-b6da-ee5ace604eda",
    "_uuid": "9c935ac4a1d1964b85513da422ebf60085dca0e3",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0\t Valid. Acc. =  6.66\n",
      "Step   500\t Valid. Acc. = 71.99\n",
      "Step  1000\t Valid. Acc. = 76.40\n",
      "Step  1500\t Valid. Acc. = 78.62\n",
      "Step  2000\t Valid. Acc. = 80.40\n",
      "Step  2500\t Valid. Acc. = 81.32\n",
      "Step  3000\t Valid. Acc. = 83.09\n",
      "Step  3500\t Valid. Acc. = 83.55\n",
      "Step  4000\t Valid. Acc. = 84.11\n",
      "Step  4500\t Valid. Acc. = 85.48\n",
      "Step  5000\t Valid. Acc. = 82.83\n",
      "Step  5500\t Valid. Acc. = 86.59\n",
      "Step  6000\t Valid. Acc. = 87.09\n",
      "Step  6500\t Valid. Acc. = 86.70\n",
      "Step  7000\t Valid. Acc. = 86.77\n",
      "Step  7500\t Valid. Acc. = 87.67\n",
      "Step  8000\t Valid. Acc. = 87.27\n",
      "Step  8500\t Valid. Acc. = 86.74\n",
      "Step  9000\t Valid. Acc. = 88.55\n",
      "Step  9500\t Valid. Acc. = 88.33\n",
      "Step 10000\t Valid. Acc. = 87.85\n",
      "Step 10500\t Valid. Acc. = 88.05\n",
      "Step 11000\t Valid. Acc. = 88.69\n",
      "Step 11500\t Valid. Acc. = 89.28\n",
      "Step 12000\t Valid. Acc. = 88.65\n",
      "Step 12500\t Valid. Acc. = 89.48\n",
      "Step 13000\t Valid. Acc. = 88.74\n",
      "Step 13500\t Valid. Acc. = 89.28\n",
      "Step 14000\t Valid. Acc. = 89.39\n",
      "Step 14500\t Valid. Acc. = 89.51\n",
      "Step 15000\t Valid. Acc. = 88.55\n",
      "Step 15500\t Valid. Acc. = 89.66\n",
      "Step 16000\t Valid. Acc. = 89.24\n",
      "Step 16500\t Valid. Acc. = 89.29\n",
      "Step 17000\t Valid. Acc. = 90.08\n",
      "Step 17500\t Valid. Acc. = 90.29\n",
      "Step 18000\t Valid. Acc. = 89.99\n",
      "Step 18500\t Valid. Acc. = 90.54\n",
      "Step 19000\t Valid. Acc. = 89.79\n",
      "Step 19500\t Valid. Acc. = 89.84\n",
      "Step 20000\t Valid. Acc. = 90.24\n",
      "Step 20500\t Valid. Acc. = 90.61\n",
      "Step 21000\t Valid. Acc. = 90.14\n",
      "Step 21500\t Valid. Acc. = 90.68\n",
      "Step 22000\t Valid. Acc. = 90.09\n",
      "Step 22500\t Valid. Acc. = 90.42\n",
      "Step 23000\t Valid. Acc. = 90.63\n",
      "Step 23500\t Valid. Acc. = 90.48\n",
      "Step 24000\t Valid. Acc. = 90.63\n",
      "Step 24500\t Valid. Acc. = 89.13\n",
      "Step 25000\t Valid. Acc. = 90.37\n",
      "Step 25500\t Valid. Acc. = 89.85\n",
      "Step 26000\t Valid. Acc. = 89.94\n",
      "Step 26500\t Valid. Acc. = 91.02\n",
      "Step 27000\t Valid. Acc. = 90.81\n",
      "Step 27500\t Valid. Acc. = 90.26\n",
      "Step 28000\t Valid. Acc. = 90.45\n",
      "Step 28500\t Valid. Acc. = 91.11\n",
      "Step 29000\t Valid. Acc. = 90.26\n",
      "Step 29500\t Valid. Acc. = 91.32\n",
      "Step 30000\t Valid. Acc. = 90.44\n",
      "Step 30500\t Valid. Acc. = 90.50\n",
      "Step 31000\t Valid. Acc. = 90.83\n",
      "Step 31500\t Valid. Acc. = 91.27\n",
      "Step 32000\t Valid. Acc. = 91.39\n",
      "Step 32500\t Valid. Acc. = 91.29\n",
      "Step 33000\t Valid. Acc. = 90.56\n",
      "Step 33500\t Valid. Acc. = 90.90\n",
      "Step 34000\t Valid. Acc. = 91.06\n",
      "Step 34500\t Valid. Acc. = 91.45\n",
      "Step 35000\t Valid. Acc. = 91.21\n",
      "Step 35500\t Valid. Acc. = 91.08\n",
      "Step 36000\t Valid. Acc. = 91.03\n",
      "Step 36500\t Valid. Acc. = 91.06\n",
      "Step 37000\t Valid. Acc. = 91.39\n",
      "Step 37500\t Valid. Acc. = 90.96\n",
      "Step 38000\t Valid. Acc. = 90.90\n",
      "Step 38500\t Valid. Acc. = 90.09\n",
      "Step 39000\t Valid. Acc. = 90.86\n",
      "Step 39500\t Valid. Acc. = 90.76\n",
      "Step 39999\t Valid. Acc. = 91.24\n",
      "CPU times: user 1d 16h 49min 20s, sys: 5h 5min 36s, total: 1d 21h 54min 56s\n",
      "Wall time: 1d 21h 55min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # calculate validation accuracy and loss\n",
    "    with torch.no_grad():\n",
    "        if step%(train_size//batch_size) == 0 or step == num_steps - 1:\n",
    "            val_acc = np.zeros(valid_size//test_batch_size)\n",
    "            val_loss = np.zeros(valid_size//test_batch_size)\n",
    "            # we need to split the calculation of the validation loss in batches\n",
    "            # to avoid memory problems.\n",
    "            for i in range(0, valid_size, test_batch_size):\n",
    "                valid_logits = model(valid_values[i:i+test_batch_size])\n",
    "                val_loss[i//test_batch_size] = lossfunc(valid_logits, valid_labels[i:i+test_batch_size]).item()\n",
    "                val_acc[i//test_batch_size] = accuracy(valid_logits, valid_labels[i:i+test_batch_size]).item()\n",
    "            history.append((step, val_loss.mean(), val_acc.mean()))\n",
    "            print(f'Step {step:5.0f}\\t Valid. Acc. = {val_acc.mean():5.2f}')\n",
    "\n",
    "    # train\n",
    "    idxs = np.random.randint(0, train_size, batch_size)\n",
    "    batch_values = train_values[idxs]\n",
    "    batch_labels = train_labels[idxs]\n",
    "    logits = model(batch_values)\n",
    "    loss = lossfunc(logits, batch_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps, loss, acc = zip(*history)\n",
    "\n",
    "fig, ax_loss = plt.subplots()\n",
    "ax_acc = ax_loss.twinx()\n",
    "\n",
    "plt.sca(ax_acc)\n",
    "plt.plot(steps, acc, '-o', color='C1')\n",
    "plt.ylabel('Accuracy [%]', color='C1');\n",
    "plt.tick_params('y', colors='C1')\n",
    "m = (min(acc)-1)//10*10; plt.ylim(m,100)\n",
    "plt.yticks([m,(m+100)//2,100])\n",
    "\n",
    "plt.sca(ax_loss)\n",
    "plt.plot(steps, loss, '-o', color='C0')\n",
    "plt.ylabel('Log Loss', color='C0');\n",
    "plt.tick_params('y', colors='C0')\n",
    "m = 1.1*max(loss)\n",
    "plt.ylim(0.01, m)\n",
    "\n",
    "plt.xlim(0, (max(steps)+100)//100*100)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.title('Validation Loss / Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the accuracy on the test set can be evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 91.31\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # we need to split the calculation of the test loss in batches\n",
    "    # to avoid memory problems.\n",
    "    test_accuracy = np.zeros(test_size//test_batch_size)\n",
    "    for i in range(0, test_size, test_batch_size):\n",
    "        test_logits = model(test_values[i:i+test_batch_size])\n",
    "        test_accuracy[i//test_batch_size] = accuracy(test_logits, test_labels[i:i+test_batch_size]).item()\n",
    "test_accuracy = test_accuracy.mean()\n",
    "print(f'Test Accuracy = {test_accuracy:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction=1\ttarget=1\n"
     ]
    }
   ],
   "source": [
    "N = 315\n",
    "show_digit(test_values[N])\n",
    "test_logits = model(test_values[N:N+1])\n",
    "prediction = torch.argmax(test_logits[0]).item()\n",
    "target = test_labels[N].item()\n",
    "print(f'prediction={prediction}\\ttarget={target}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
